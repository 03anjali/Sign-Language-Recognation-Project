# Sign Language Recognition Project
 ## `Abstract`
 
 Sign language is a visual language used by people with hearing disabilities to communicate with each other and with hearing people. However, understanding sign language can be a challenge for those who are not familiar with it. Machine learning and deep neural networks can be used to detect sign language gestures and translate them into text or speech to help bridge this communication gap.
 
In this project, a machine learning model and deep neural network are developed to detect sign language gestures. The model is trained on a large dataset of sign language gestures and uses image processing techniques to detect and track the movements of the hands and fingers. The deep neural network is used to classify the detected gestures into corresponding sign language words or phrases.

The project is evaluated on a separate testing dataset and achieves high accuracy in detecting and translating sign language gestures. 
![image](https://github.com/03anjali/Sign-Language-Recognation-Project/assets/91782986/df87b189-7ee8-4a57-af04-e786acd269a4)


